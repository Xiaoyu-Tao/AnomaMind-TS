# -*- coding: utf-8 -*-
"""
è§£ææ•°æ®å¹¶ç”Ÿæˆ parquetã€‚
1. æ”¯æŒä¸ºæ¯ä¸ªæ•°æ®é›†è®¾å®šä¸åŒçš„æœ€å¤§é‡‡æ ·æ•°é‡ï¼ˆmax_samplesï¼‰ã€‚
2. æ”¯æŒé€šè¿‡é‡å¤é‡‡æ ·(Oversampling)å¼ºåˆ¶è¾¾åˆ°ç›®æ ‡å¼‚å¸¸æ¯”ä¾‹ã€‚
"""

import pandas as pd
from pathlib import Path
import random
from typing import List, Optional, Dict

# ==========================================================
# ç¡¬ç¼–ç é…ç½® 1ï¼šæ¯ä¸ªæ•°æ®é›†çš„æœ€å°å¼‚å¸¸æ ·æœ¬æ¯”ä¾‹ (Minimum Ratio)
# æ³¨æ„ï¼šè¿™æ˜¯æœ€ä½æ¯”ä¾‹ï¼Œå®é™…é‡‡æ ·æ—¶å¼‚å¸¸æ¯”ä¾‹å¯ä»¥é«˜äºæ­¤å€¼ï¼Œä½†ä¸èƒ½ä½äºæ­¤å€¼
# ==========================================================
ANOMALY_RATIO_CONFIG = {
    "YAHOO": 0.0,
    "ECG": 0.0,
    "IOPS": 0.0,
    "SVDB": 0.0,
    "TODS": 0.0,
    "WSD": 0.0,
    "DEFAULT": 0.0
}

# ==========================================================
# ç¡¬ç¼–ç é…ç½® 2ï¼šæ¯ä¸ªæ•°æ®é›†çš„æœ€å¤§é‡‡æ ·æ•°é‡ (Max Samples)
# ==========================================================
DOMAIN_MAX_SAMPLES = {
    "YAHOO": 1200,
    "IOPS": 1000,
    "TODS": 10000,
    "WSD": 100000,
    "DEFAULT": 0 
}

def is_anomaly_folder(folder: Path) -> bool:
    """check the csv"""
    gt_path = folder / "ground_truth.csv"
    if not gt_path.exists():
        return False
    try:
        df_gt = pd.read_csv(gt_path)
        return len(df_gt) > 0
    except Exception:
        return False

def parse_single_domain(
    input_dir: Path, 
    pattern: str = "*_seg*",
    domain_name: Optional[str] = None,
    max_samples: int = 500,
    min_ratio: float = 0.3,
    seed: Optional[int] = None
) -> List[dict]:
    if seed is not None:
        random.seed(seed)
    
    domain_name = domain_name or input_dir.name
    print(f"\næ‰«æåŸŸ: {domain_name} | é‡‡æ ·ä¸Šé™: {max_samples} | æœ€å°å¼‚å¸¸æ¯”ä¾‹: {min_ratio:.1%}")
    
    all_folders = sorted([f for f in input_dir.iterdir() if f.is_dir() and f.match(pattern)])
    
    anomaly_pool = []
    normal_pool = []

    for folder in all_folders:
        if not (folder / "segment_data.csv").exists() or not (folder / "ground_truth.csv").exists():
            continue
        if is_anomaly_folder(folder):
            anomaly_pool.append(folder)
        else:
            normal_pool.append(folder)

    if not anomaly_pool and not normal_pool:
        print(f"  âš ï¸ {domain_name} æœªå‘ç°æœ‰æ•ˆæ•°æ®")
        return []

    # 1. ç¡®å®šæœ€ç»ˆè¦é‡‡æ ·çš„æ€»æ•°ï¼ˆå–ç›®å½•å®é™…æ€»é‡ä¸ç¡¬ç¼–ç ä¸Šé™çš„æœ€å°å€¼ï¼‰
    total_to_sample = min(len(all_folders), max_samples)
    
    # 2. è®¡ç®—æœ€å°å¼‚å¸¸æ•°ï¼ˆç¡®ä¿å¼‚å¸¸æ¯”ä¾‹è‡³å°‘è¾¾åˆ° min_ratioï¼‰
    min_anomaly_needed = int(total_to_sample * min_ratio)
    
    sampled_anomaly = []
    
    # --- é‡‡æ ·å¼‚å¸¸æ ·æœ¬ï¼ˆç¡®ä¿è‡³å°‘è¾¾åˆ°æœ€å°æ¯”ä¾‹ï¼Œä½†å¯ä»¥ä½¿ç”¨æ›´å¤šï¼‰---
    if len(anomaly_pool) > 0:
        if len(anomaly_pool) >= min_anomaly_needed:
            # å¼‚å¸¸æ± è¶³å¤Ÿï¼Œä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„å¼‚å¸¸æ ·æœ¬ï¼ˆåœ¨ total_to_sample èŒƒå›´å†…ï¼‰
            # è¿™æ ·å¯ä»¥å……åˆ†åˆ©ç”¨æ•°æ®ï¼Œå¼‚å¸¸æ¯”ä¾‹å¯èƒ½é«˜äºæœ€å°æ¯”ä¾‹ï¼Œè¿™æ˜¯è¢«å…è®¸çš„
            num_anomaly_to_sample = min(len(anomaly_pool), total_to_sample)
            sampled_anomaly = random.sample(anomaly_pool, num_anomaly_to_sample)
        else:
            # å¼‚å¸¸æ± ä¸è¶³ï¼Œéœ€è¦é‡å¤é‡‡æ ·ä»¥è¾¾åˆ°æœ€å°æ¯”ä¾‹è¦æ±‚
            sampled_anomaly = list(anomaly_pool)
            shortage = min_anomaly_needed - len(anomaly_pool)
            sampled_anomaly.extend(random.choices(anomaly_pool, k=shortage))
            print(f"  ğŸ’¡ {domain_name}: å¼‚å¸¸ä¸è¶³, é‡å¤é‡‡æ ·è¡¥é½è‡³ {min_anomaly_needed}ï¼ˆæœ€å°æ¯”ä¾‹è¦æ±‚ï¼‰")
    else:
        print(f"  âŒ è­¦å‘Š: {domain_name} æ— å¼‚å¸¸æ ·æœ¬ï¼Œæ— æ³•æ»¡è¶³æœ€å°å¼‚å¸¸æ¯”ä¾‹è¦æ±‚")

    # 3. å¡«å……æ­£å¸¸æ ·æœ¬ï¼ˆå‰©ä½™çš„ç©ºä½ï¼‰
    remaining_slots = max(0, total_to_sample - len(sampled_anomaly))
    if len(normal_pool) >= remaining_slots:
        sampled_normal = random.sample(normal_pool, remaining_slots)
    else:
        if len(normal_pool) > 0:
            sampled_normal = random.choices(normal_pool, k=remaining_slots)
        else:
            sampled_normal = []

    final_list = sampled_anomaly + sampled_normal
    random.shuffle(final_list)
    
    # è®¡ç®—å®é™…å¼‚å¸¸æ¯”ä¾‹
    actual_ratio = len(sampled_anomaly) / len(final_list) if len(final_list) > 0 else 0.0
    print(f"  é‡‡æ ·ç»“æœ: æ€»è®¡={len(final_list)} (å¼‚å¸¸={len(sampled_anomaly)}, æ­£å¸¸={len(sampled_normal)}, å®é™…å¼‚å¸¸æ¯”ä¾‹={actual_ratio:.1%})")

    return [{
        "segment_folder": str(folder.resolve()),
        "domain": domain_name,
        "has_anomaly": folder in anomaly_pool
    } for folder in final_list]

def parse_all_preprocessed_data(
    input_dirs: List[Path],
    output_parquet_path: Path,
    seed: Optional[int] = None
):
    if seed is not None:
        random.seed(seed)
    
    print("=" * 80)
    print("è·¨åŸŸæ•°æ®è§£æ (åŠ¨æ€ä¸Šé™ + æœ€å°å¼‚å¸¸æ¯”ä¾‹ä¿è¯)")
    print("=" * 80)
    
    all_data = []

    for input_dir in input_dirs:
        if not input_dir.exists(): continue
        
        domain_name = input_dir.name
        
        # è·å–è¯¥åŸŸç‰¹å®šçš„é…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ DEFAULT
        min_ratio = ANOMALY_RATIO_CONFIG.get(domain_name, ANOMALY_RATIO_CONFIG["DEFAULT"])
        limit = DOMAIN_MAX_SAMPLES.get(domain_name, DOMAIN_MAX_SAMPLES["DEFAULT"])
        
        domain_data = parse_single_domain(
            input_dir=input_dir,
            domain_name=domain_name,
            max_samples=limit,
            min_ratio=min_ratio,
            seed=seed
        )
        
        if domain_data:
            all_data.extend(domain_data)

    if not all_data: return

    df = pd.DataFrame(all_data)
    df = df.sample(frac=1, random_state=seed).reset_index(drop=True)
    output_parquet_path.parent.mkdir(parents=True, exist_ok=True)
    df.to_parquet(output_parquet_path, index=False, engine='pyarrow')

    print("\n" + "=" * 80)
    # ç»Ÿè®¡æœ€ç»ˆç»“æœ
    final_stats = df.groupby('domain')['has_anomaly'].agg(['count', 'sum'])
    final_stats.columns = ['Total_Sampled', 'Original_Anomaly_Count']
    final_stats['Final_Ratio'] = (final_stats['Original_Anomaly_Count'] / final_stats['Total_Sampled'] * 100).map('{:.1f}%'.format)
    print(final_stats)
    print(f"\næˆåŠŸç”Ÿæˆ: {output_parquet_path} | æ€»æ ·æœ¬: {len(df)}")
    print("=" * 80)

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--output", type=str, default="./unsample.parquet")
    parser.add_argument("--seed", type=int, default=42)
    args = parser.parse_args()
    
    # è‡ªåŠ¨æœç´¢ ./TrainData
    train_path = Path("./TrainData")
    dirs = [d for d in train_path.iterdir() if d.is_dir()] if train_path.exists() else []

    parse_all_preprocessed_data(dirs, Path(args.output), seed=args.seed)